{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55f3d1e4-65b5-464b-a816-03449af4e824",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmhender/imstat_env/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "codepath = '/user_data/mmhender/image_stats_gabor/code/'\n",
    "sys.path.insert(0,codepath)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import scipy.stats\n",
    "import cmocean\n",
    "\n",
    "from plotting import plot_utils, summary_plots, load_fits\n",
    "from utils import roi_utils, default_paths, prf_utils\n",
    "from feature_extraction import gabor_feature_extractor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b22277f-faec-449f-bb1e-5a38896a02f9",
   "metadata": {},
   "source": [
    "#### Load fit results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ea8f484-8f20-40a9-8b2e-dd59a99ede56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "subjects = np.arange(1,9)\n",
    "n_subjects = len(subjects)\n",
    "\n",
    "fitting_type = 'gabor_solo_ridge_12ori_8sf'\n",
    "out = [load_fits.load_fit_results(subject=ss, fitting_type=fitting_type, n_from_end=0, \\\n",
    "                                  verbose=False) for ss in subjects]\n",
    "fitting_type2 = 'gabor_solo_ridge_12ori_8sf_permutation_test'\n",
    "out_shuff = [load_fits.load_fit_results(subject=ss, fitting_type=fitting_type2, n_from_end=0, \\\n",
    "                                  verbose=False)  for ss in subjects]\n",
    "\n",
    "# create ROIs\n",
    "roi_def = roi_utils.multi_subject_roi_def(subjects, remove_ret_overlap=True, \\\n",
    "                                          remove_categ_overlap=True)\n",
    "roi_names =roi_def.roi_names\n",
    "n_rois = len(roi_names)\n",
    "\n",
    "# make a list of voxels per subject\n",
    "n_vox_each_subj = [out[si]['best_params'][0].shape[0] for si in range(n_subjects)]\n",
    "subject_inds = np.concatenate([si*np.ones((n_vox_each_subj[si],),dtype=int) \\\n",
    "                               for si in range(n_subjects)], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943233cd-251e-46fb-82de-48f79afa1b2b",
   "metadata": {},
   "source": [
    "#### Process results of permutation test, compute p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "810d804e-a695-4ae3-833c-972accf6715c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import stats_utils\n",
    "from plotting import summary_plots\n",
    "\n",
    "p_voxels_orig = [[] for si in range(n_subjects)]\n",
    "\n",
    "for si in range(n_subjects):\n",
    "\n",
    "    # stats for single voxels\n",
    "    r2_real_orig = out[si]['val_r2']\n",
    "    r2_shuff_orig = out_shuff[si]['val_r2']\n",
    "\n",
    "    # for how many of the shuffle iterations did shuffle-R2 exceed real-R2?\n",
    "    p_orig = np.mean(r2_real_orig[:,0,None]<=r2_shuff_orig[:,0,:], axis=1)\n",
    "    _,pvals_fdr_orig = stats_utils.fdr_keepshape(p_orig, alpha=0.01, \\\n",
    "                                                   method='poscorr')\n",
    "    p_voxels_orig[si] = pvals_fdr_orig\n",
    "    \n",
    "# thresholding voxels based on the permutation test\n",
    "p = np.concatenate(p_voxels_orig, axis=0)\n",
    "abv_thresh = p<0.01\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84f6f4b-ccd0-4b29-9328-8f734816d6ae",
   "metadata": {},
   "source": [
    "#### Get info about the Gabor feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dc3162b-0f96-4131-b6dc-3788c9e9c9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sf=8; n_ori=12;\n",
    "_gabor_ext_complex = gabor_feature_extractor.gabor_extractor_multi_scale(n_ori=n_ori, n_sf=n_sf)\n",
    "\n",
    "screen_eccen_deg=8.4\n",
    "sf_cyc_per_stim = _gabor_ext_complex.feature_table['SF: cycles per stim']\n",
    "sf_cyc_per_deg = sf_cyc_per_stim/screen_eccen_deg\n",
    "sf_unique, sf_inds = np.unique(sf_cyc_per_deg, return_inverse=True)\n",
    "\n",
    "ori_deg = _gabor_ext_complex.feature_table['Orientation: degrees']\n",
    "ori_unique, orient_inds = np.unique(ori_deg, return_inverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67a5efaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_corr = np.concatenate([out[si]['corr_each_feature'] for si in range(n_subjects)], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec5f6ed-0281-4d20-be4f-9fbf1ee37976",
   "metadata": {},
   "source": [
    "#### Load image stats analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d008e004-a629-470d-8122-fbef3aa587eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['face', 'building', 'animate', 'inanimate', 'small', 'large',\n",
       "        'indoor', 'outdoor'], dtype='<U9'),\n",
       " array(['face', 'building', 'animate', 'inanimate', 'small', 'large',\n",
       "        'indoor', 'outdoor'], dtype='<U9'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_type='gabor_solo'\n",
    "subject=998\n",
    "which_prf_grid=5;\n",
    "\n",
    "path_to_load = default_paths.gabor_texture_feat_path\n",
    "path_to_load = os.path.join(path_to_load, 'feature_stats')\n",
    "\n",
    "fn1 = os.path.join(path_to_load, 'S%d_%s_mean_grid%d.npy'%(subject, feature_type, which_prf_grid))\n",
    "fn2 = os.path.join(path_to_load, 'S%d_%s_var_grid%d.npy'%(subject, feature_type, which_prf_grid))\n",
    "\n",
    "mean = np.load(fn1,allow_pickle=True)\n",
    "var = np.load(fn2,allow_pickle=True)\n",
    "\n",
    "fn1 = os.path.join(path_to_load, 'S%d_%s_categ_partial_corrs_grid%d.npy'%(subject, feature_type, which_prf_grid))\n",
    "fn2 = os.path.join(path_to_load, 'S%d_%s_categ_nsamp_partial_corrs_grid%d.npy'%(subject, feature_type, which_prf_grid))\n",
    "\n",
    "partial_corr = np.load(fn1,allow_pickle=True)\n",
    "partial_nsamp = np.load(fn2,allow_pickle=True)\n",
    "assert not np.any(partial_nsamp==0)\n",
    "assert not np.any(np.isnan(partial_nsamp))\n",
    "\n",
    "fn2load = os.path.join(default_paths.stim_labels_root, 'Highlevel_counts_all.npy')\n",
    "counts = np.load(fn2load, allow_pickle=True).item()\n",
    "axis_names = counts['categ_names']\n",
    "axes_use = [0,1,2,3, 4,5,6,7]\n",
    "axis_names = np.array(axis_names)[axes_use]\n",
    "signed_names = axis_names\n",
    "axis_names, signed_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833ef27b-483d-4b80-a2b5-5894ef28c04e",
   "metadata": {},
   "source": [
    "#### Correlate each voxel's sensitivity profile with the diagnostic feature channels for each semantic axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6b678d8-d058-428b-a636-bbc035c383e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/150842\n",
      "5000/150842\n",
      "10000/150842\n",
      "15000/150842\n",
      "20000/150842\n",
      "25000/150842\n",
      "30000/150842\n",
      "35000/150842\n",
      "40000/150842\n",
      "45000/150842\n",
      "50000/150842\n",
      "55000/150842\n",
      "60000/150842\n",
      "65000/150842\n",
      "70000/150842\n",
      "75000/150842\n",
      "80000/150842\n",
      "85000/150842\n",
      "90000/150842\n",
      "95000/150842\n",
      "100000/150842\n",
      "105000/150842\n",
      "110000/150842\n",
      "115000/150842\n",
      "120000/150842\n",
      "125000/150842\n",
      "130000/150842\n",
      "135000/150842\n",
      "140000/150842\n",
      "145000/150842\n",
      "150000/150842\n"
     ]
    }
   ],
   "source": [
    "n_vox = feature_corr.shape[0]\n",
    "n_dims = len(signed_names)\n",
    "tuning_dim_corrs = np.zeros((n_vox,n_dims))\n",
    "tuning_var_corrs = np.zeros((n_vox,))\n",
    "tuning_mean_corrs = np.zeros((n_vox,))\n",
    "\n",
    "mean_vals = np.mean(mean, axis=1)\n",
    "var_vals = np.mean(var, axis=1)\n",
    "    \n",
    "sem_vals = np.mean(partial_corr, axis=1)\n",
    "\n",
    "assert not(np.any(np.isnan(sem_vals)))\n",
    "\n",
    "# for vv in [0]:\n",
    "for vv in range(n_vox):\n",
    "    \n",
    "    if np.mod(vv,5000)==0:\n",
    "        print('%d/%d'%(vv, n_vox))\n",
    "        \n",
    "    # selectivity of the current voxel for each channel\n",
    "    # vox_vals = allcorr_reshaped[vv,:,:].ravel()\n",
    "    vox_vals = feature_corr[vv,:]\n",
    "    \n",
    "    tuning_mean_corrs[vv] = np.corrcoef(mean_vals, vox_vals)[0,1]\n",
    "    tuning_var_corrs[vv] = np.corrcoef(var_vals, vox_vals)[0,1]\n",
    "    \n",
    "    for dim in range(n_dims):\n",
    "        \n",
    "        # raw correlation\n",
    "        tuning_dim_corrs[vv,dim] = np.corrcoef(sem_vals[:,dim], vox_vals)[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40247d1-d1d9-4023-b074-1a936526649d",
   "metadata": {},
   "source": [
    "#### Average over ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2b3245a-2513-47ba-b7a6-cad47ca04b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_tuning_mean_corrs = np.zeros((n_subjects, n_rois))\n",
    "roi_tuning_var_corrs = np.zeros((n_subjects, n_rois))\n",
    "roi_tuning_dim_corrs = np.zeros((n_subjects, n_rois, n_dims))\n",
    "\n",
    "for si in range(n_subjects):\n",
    "    \n",
    "    for ri in range(n_rois):\n",
    "        \n",
    "        inds_this_roi = roi_def.get_indices(ri) & abv_thresh & (subject_inds==si)\n",
    "     \n",
    "        roi_tuning_mean_corrs[si,ri] = np.mean(tuning_mean_corrs[inds_this_roi], axis=0)\n",
    "        roi_tuning_var_corrs[si,ri] = np.mean(tuning_var_corrs[inds_this_roi], axis=0)\n",
    "        roi_tuning_dim_corrs[si,ri,:] = np.mean(tuning_dim_corrs[inds_this_roi,:], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cda9aded-5e94-4f75-ba3f-6c35073ca49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/user_data/mmhender/image_stats_gabor/figures/tuning_semantic_alignment.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>hV4</th>\n",
       "      <th>V3ab</th>\n",
       "      <th>IPS</th>\n",
       "      <th>OPA</th>\n",
       "      <th>PPA</th>\n",
       "      <th>RSC</th>\n",
       "      <th>OFA</th>\n",
       "      <th>FFA</th>\n",
       "      <th>EBA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.39</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.30</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variance</th>\n",
       "      <td>-0.35</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.22</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.22</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>face</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>building</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.17</td>\n",
       "      <td>-0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>animate</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>-0.65</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inanimate</th>\n",
       "      <td>-0.23</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>small</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.21</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>large</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>-0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indoor</th>\n",
       "      <td>-0.30</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outdoor</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.42</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>-0.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             V1    V2    V3   hV4  V3ab   IPS   OPA   PPA   RSC   OFA   FFA  \\\n",
       "mean      -0.39 -0.33 -0.19 -0.16  0.30  0.23  0.33  0.30 -0.02 -0.00  0.15   \n",
       "variance  -0.35 -0.29 -0.17 -0.15  0.31  0.20  0.26  0.22 -0.11  0.05  0.22   \n",
       "face       0.29  0.38  0.44  0.46  0.52  0.02 -0.09 -0.11 -0.50  0.68  0.76   \n",
       "building   0.14  0.19  0.23  0.21  0.14 -0.06  0.12  0.29  0.26  0.22  0.17   \n",
       "animate    0.24  0.33  0.37  0.38  0.52  0.03 -0.16 -0.24 -0.65  0.67  0.78   \n",
       "inanimate -0.23 -0.23 -0.11 -0.01  0.06  0.24  0.39  0.35  0.18 -0.20 -0.16   \n",
       "small      0.46  0.47  0.44  0.49  0.21 -0.02 -0.30 -0.47 -0.67  0.48  0.47   \n",
       "large      0.18  0.09  0.03  0.10 -0.37 -0.04 -0.06 -0.13  0.12 -0.29 -0.43   \n",
       "indoor    -0.30 -0.22 -0.12 -0.16  0.29  0.10  0.29  0.41  0.20  0.09  0.20   \n",
       "outdoor    0.15  0.05 -0.07 -0.10 -0.54 -0.20 -0.15 -0.07  0.42 -0.39 -0.58   \n",
       "\n",
       "            EBA  \n",
       "mean      -0.07  \n",
       "variance  -0.01  \n",
       "face       0.36  \n",
       "building  -0.05  \n",
       "animate    0.43  \n",
       "inanimate -0.20  \n",
       "small      0.39  \n",
       "large     -0.13  \n",
       "indoor    -0.09  \n",
       "outdoor   -0.20  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "subject_mean_vals = np.concatenate([np.mean(roi_tuning_mean_corrs, axis=0)[:,None], \\\n",
    "                                    np.mean(roi_tuning_var_corrs, axis=0)[:,None], \\\n",
    "                                    np.mean(roi_tuning_dim_corrs, axis=0)], axis=1)\n",
    "row_names = ['mean','variance'] + list(axis_names)\n",
    "df = pd.DataFrame(subject_mean_vals.round(2).T, columns=roi_names, index=row_names)\n",
    "\n",
    "\n",
    "for col in roi_names:\n",
    "    df[col].map('${:,.4f}'.format)\n",
    "    \n",
    "fn2save = os.path.join(default_paths.fig_path, 'tuning_semantic_alignment.csv')\n",
    "print(fn2save)\n",
    "df.to_csv(fn2save)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
